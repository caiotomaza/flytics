{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from xgboost) (1.16.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from lightgbm) (1.16.3)\n",
      "Collecting catboost\n",
      "  Using cached catboost-1.2.8.tar.gz (58.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting graphviz (from catboost)\n",
      "  Using cached graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting matplotlib (from catboost)\n",
      "  Using cached matplotlib-3.10.7-cp314-cp314-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from catboost) (2.3.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from catboost) (1.16.3)\n",
      "Collecting plotly (from catboost)\n",
      "  Using cached plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: six in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->catboost)\n",
      "  Using cached contourpy-1.3.3-cp314-cp314-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->catboost)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->catboost)\n",
      "  Using cached fonttools-4.60.1-cp314-cp314-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost)\n",
      "  Using cached kiwisolver-1.4.9-cp314-cp314-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\caio tomaz\\desktop\\flytics\\venv\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib->catboost)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->catboost)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
      "  Using cached narwhals-2.10.2-py3-none-any.whl.metadata (11 kB)\n",
      "Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Using cached matplotlib-3.10.7-cp314-cp314-win_amd64.whl (8.3 MB)\n",
      "Using cached contourpy-1.3.3-cp314-cp314-win_amd64.whl (232 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp314-cp314-win_amd64.whl (2.3 MB)\n",
      "Using cached kiwisolver-1.4.9-cp314-cp314-win_amd64.whl (75 kB)\n",
      "Using cached pillow-12.0.0-cp314-cp314-win_amd64.whl (7.1 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
      "Using cached narwhals-2.10.2-py3-none-any.whl (419 kB)\n",
      "Building wheels for collected packages: catboost\n",
      "  Building wheel for catboost (pyproject.toml): started\n",
      "  Building wheel for catboost (pyproject.toml): finished with status 'error'\n",
      "Failed to build catboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for catboost (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [130 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\carry.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\core.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\datasets.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\dev_utils.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\metrics.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\monoforest.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\plot_helpers.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\text_processing.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\utils.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\version.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      copying catboost\\__init__.py -> build\\lib.win-amd64-cpython-314\\catboost\n",
      "      creating build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\catboost_evaluation.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\evaluation_result.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\execution_case.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\factor_utils.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\log_config.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\utils.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\_fold_model.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\_fold_models_handler.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\_fold_storage.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\_readers.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\_splitter.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      copying catboost\\eval\\__init__.py -> build\\lib.win-amd64-cpython-314\\catboost\\eval\n",
      "      creating build\\lib.win-amd64-cpython-314\\catboost\\widget\n",
      "      copying catboost\\widget\\callbacks.py -> build\\lib.win-amd64-cpython-314\\catboost\\widget\n",
      "      copying catboost\\widget\\ipythonwidget.py -> build\\lib.win-amd64-cpython-314\\catboost\\widget\n",
      "      copying catboost\\widget\\metrics_plotter.py -> build\\lib.win-amd64-cpython-314\\catboost\\widget\n",
      "      copying catboost\\widget\\__init__.py -> build\\lib.win-amd64-cpython-314\\catboost\\widget\n",
      "      running build_ext\n",
      "      Buildling _catboost with cmake and ninja\n",
      "      target_platform=windows-x86_64. Building targets _catboost with PIC\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\Desktop\\flytics\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\Desktop\\flytics\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\Desktop\\flytics\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m280\u001b[0m, in \u001b[35mbuild_wheel\u001b[0m\n",
      "          return \u001b[31m_build_backend().build_wheel\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "              \u001b[1;31mwheel_directory, config_settings, metadata_directory\u001b[0m\n",
      "              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          \u001b[1;31m)\u001b[0m\n",
      "          \u001b[1;31m^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m435\u001b[0m, in \u001b[35mbuild_wheel\u001b[0m\n",
      "          return _build(['bdist_wheel', '--dist-info-dir', str(metadata_directory)])\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m423\u001b[0m, in \u001b[35m_build\u001b[0m\n",
      "          return \u001b[31mself._build_with_temp_dir\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "              \u001b[1;31mcmd,\u001b[0m\n",
      "              \u001b[1;31m^^^^\u001b[0m\n",
      "          ...<3 lines>...\n",
      "              \u001b[1;31mself._arbitrary_args(config_settings),\u001b[0m\n",
      "              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          \u001b[1;31m)\u001b[0m\n",
      "          \u001b[1;31m^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m404\u001b[0m, in \u001b[35m_build_with_temp_dir\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m723\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\"\u001b[0m, line \u001b[35m115\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "          return \u001b[31mdistutils.core.setup\u001b[0m\u001b[1;31m(**attrs)\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "          return run_commands(dist)\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\"\u001b[0m, line \u001b[35m202\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "          \u001b[31mdist.run_commands\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "          \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\"\u001b[0m, line \u001b[35m1102\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\"\u001b[0m, line \u001b[35m1021\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\command\\bdist_wheel.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "          \u001b[31mself.run_command\u001b[0m\u001b[1;31m(\"build\")\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\"\u001b[0m, line \u001b[35m357\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\"\u001b[0m, line \u001b[35m1102\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\"\u001b[0m, line \u001b[35m1021\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m324\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\"\u001b[0m, line \u001b[35m135\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "          \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd_name)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\"\u001b[0m, line \u001b[35m357\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\dist.py\"\u001b[0m, line \u001b[35m1102\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-build-env-vx0wgreo\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\"\u001b[0m, line \u001b[35m1021\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "          \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m436\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m454\u001b[0m, in \u001b[35mbuild_with_cmake_and_ninja\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-install-m0arp_8r\\catboost_2c050df084594fd391b3bdff43fab991\\catboost_all_src\\build\\build_native.py\"\u001b[0m, line \u001b[35m571\u001b[0m, in \u001b[35mbuild\u001b[0m\n",
      "          build_environ = get_build_environ(opts, target_platform, cmd_runner)\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-install-m0arp_8r\\catboost_2c050df084594fd391b3bdff43fab991\\catboost_all_src\\build\\build_native.py\"\u001b[0m, line \u001b[35m479\u001b[0m, in \u001b[35mget_build_environ\u001b[0m\n",
      "          build_environ = get_msvc_environ(\n",
      "              opts.msvs_installation_path,\n",
      "          ...<3 lines>...\n",
      "              opts.dry_run\n",
      "          )\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-install-m0arp_8r\\catboost_2c050df084594fd391b3bdff43fab991\\catboost_all_src\\build\\build_native.py\"\u001b[0m, line \u001b[35m425\u001b[0m, in \u001b[35mget_msvc_environ\u001b[0m\n",
      "          msvs_dir = get_msvs_dir(msvs_installation_path, msvs_version)\n",
      "        File \u001b[35m\"C:\\Users\\Caio Tomaz\\AppData\\Local\\Temp\\pip-install-m0arp_8r\\catboost_2c050df084594fd391b3bdff43fab991\\catboost_all_src\\build\\build_native.py\"\u001b[0m, line \u001b[35m412\u001b[0m, in \u001b[35mget_msvs_dir\u001b[0m\n",
      "          raise RuntimeError(f'Microsoft Visual Studio {msvs_version} installation not found')\n",
      "      \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mMicrosoft Visual Studio 2022 installation not found\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for catboost\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> catboost\n"
     ]
    }
   ],
   "source": [
    "# Instalando blibiotecas\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install numpy\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81447,
     "status": "ok",
     "timestamp": 1761941823117,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "Tu5oPf990JKX",
    "outputId": "16c66339-ae04-411b-9148-a9fe847b4fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame combinado criado com sucesso!\n",
      "  EMPRESA ORIGEM DESTINO   TARIFA  ASSENTOS  MES   ANO\n",
      "0     ABJ   SBSV    SIRI   650,00        17    1  2023\n",
      "1     ABJ   SBSV    SIRI   850,00        23    1  2023\n",
      "2     ABJ   SBSV    SIRI  1050,00         6    1  2023\n",
      "3     ABJ   SBSV    SIRI  1250,00         1    1  2023\n",
      "4     ABJ   SBSV    SNCL   450,00         1    1  2023\n"
     ]
    }
   ],
   "source": [
    "# Transformação dos dados de voous em DataFrame único\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define o caminho para a pasta que contém as pastas de ano\n",
    "base_folder_path = './dataset/'\n",
    "\n",
    "# Cria uma lista para armazenar os DataFrames de cada arquivo\n",
    "df_list = []\n",
    "\n",
    "# Lista todos os itens na pasta base\n",
    "all_items = os.listdir(base_folder_path)\n",
    "\n",
    "# Filtra apenas as pastas (que devem ser os anos)\n",
    "year_folders = [d for d in all_items if os.path.isdir(os.path.join(base_folder_path, d))]\n",
    "\n",
    "# Itera sobre as pastas de ano\n",
    "for year_folder in year_folders:\n",
    "    year_path = os.path.join(base_folder_path, year_folder)\n",
    "\n",
    "    # Extrai o ano do nome da pasta\n",
    "    try:\n",
    "        year_from_folder = int(year_folder)\n",
    "    except ValueError:\n",
    "        print(f\"Ignorando pasta '{year_folder}' pois o nome não é um ano válido.\")\n",
    "        continue # Skip to the next folder if the name is not a valid year\n",
    "\n",
    "    # Lista todos os arquivos na pasta do ano\n",
    "    year_files = os.listdir(year_path)\n",
    "\n",
    "    # Filtra apenas os arquivos CSV dentro da pasta do ano\n",
    "    csv_files = [f for f in year_files if f.endswith('.CSV')]\n",
    "\n",
    "    # Itera sobre os arquivos CSV dentro da pasta do ano\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(year_path, csv_file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=';')  # Specify semicolon delimiter\n",
    "\n",
    "            # Use the year from the folder\n",
    "            df['ANO'] = year_from_folder\n",
    "\n",
    "            # Convert 'MES' to string before removing comma and converting to numeric\n",
    "            df['MES'] = df['MES'].astype(str).str.replace(',', '', regex=False) # Remove comma\n",
    "            df['MES'] = pd.to_numeric(df['MES'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "            # Create a simple date format (YYYY-MM) - assuming day is not important or always 1\n",
    "            df['DATA'] = pd.to_datetime(df['ANO'].astype(str) + '-' + df['MES'].astype(str), format='%Y-%m', errors='coerce')\n",
    "\n",
    "            # Extract year and month into new columns\n",
    "            df['ANO'] = df['DATA'].dt.year\n",
    "            df['MES'] = df['DATA'].dt.month\n",
    "\n",
    "            # Drop the original date columns\n",
    "            df = df.drop(columns=['nr_ano_referencia', 'nr_mes_referencia', 'DATA'], errors='ignore')\n",
    "\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo {csv_file} na pasta {year_folder}: {e}\")\n",
    "\n",
    "# Concatena todos os DataFrames na lista em um único DataFrame\n",
    "if df_list:\n",
    "    main_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"DataFrame combinado criado com sucesso!\")\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = main_df.columns.tolist()\n",
    "    cols.remove('MES')\n",
    "    cols.remove('ANO')\n",
    "    cols.insert(cols.index('ASSENTOS') + 1, 'MES')\n",
    "    cols.insert(cols.index('ASSENTOS') + 2, 'ANO')\n",
    "    main_df = main_df[cols]\n",
    "\n",
    "    print(main_df.head())\n",
    "else:\n",
    "    print(\"Nenhum arquivo CSV encontrado ou lido nas pastas de ano.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 8900,
     "status": "ok",
     "timestamp": 1761941832029,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "cFnYP4zFB0xP",
    "outputId": "b8c4eac6-aaed-418f-901e-864417ddec6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'EMPRESA' column after replacement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ATA - AEROTÁXI ABAETÉ LTDA.',\n",
       "       'AZUL LINHAS AÉREAS BRASILEIRAS S/A',\n",
       "       'GOL LINHAS AÉREAS S.A. (EX- VRG LINHAS AÉREAS S.A.)', 'PTB',\n",
       "       'TAM LINHAS AÉREAS S.A.', 'APUÍ TÁXI AÉREO S/A'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       EMPRESA ORIGEM DESTINO   TARIFA  ASSENTOS  MES   ANO\n",
      "0  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SIRI   650,00        17    1  2023\n",
      "1  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SIRI   850,00        23    1  2023\n",
      "2  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SIRI  1050,00         6    1  2023\n",
      "3  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SIRI  1250,00         1    1  2023\n",
      "4  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SNCL   450,00         1    1  2023\n"
     ]
    }
   ],
   "source": [
    "# Mapeando e alterando os nome das empresas aéreas no DataFrame\n",
    "empresa_mapping = {\n",
    "    'ABJ': 'ATA - AEROTÁXI ABAETÉ LTDA.',\n",
    "    'AZU': 'AZUL LINHAS AÉREAS BRASILEIRAS S/A',\n",
    "    'GLO': 'GOL LINHAS AÉREAS S.A. (EX- VRG LINHAS AÉREAS S.A.)',\n",
    "    'TAM': 'TAM LINHAS AÉREAS S.A.',\n",
    "    'CQB': 'APUÍ TÁXI AÉREO S/A'\n",
    "}\n",
    "\n",
    "# Replace the abbreviations in the 'EMPRESA' column\n",
    "main_df['EMPRESA'] = main_df['EMPRESA'].replace(empresa_mapping)\n",
    "\n",
    "# Display the updated unique values in the 'EMPRESA' column to verify\n",
    "print(\"Unique values in 'EMPRESA' column after replacement:\")\n",
    "display(main_df['EMPRESA'].unique())\n",
    "\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1761941832246,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "3Tpg5vTTDetC",
    "outputId": "3722101d-3eb3-41c2-835d-d6b85563f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame created with 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', and 'UF' columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CÓDIGO OACI</th>\n",
       "      <th>MUNICÍPIO ATENDIDO</th>\n",
       "      <th>UF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBAA</td>\n",
       "      <td>CONCEIÇÃO DO ARAGUAIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBAE</td>\n",
       "      <td>BAURU</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBAQ</td>\n",
       "      <td>ARARAQUARA</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBAR</td>\n",
       "      <td>ARACAJU</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBAT</td>\n",
       "      <td>ALTA FLORESTA</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CÓDIGO OACI     MUNICÍPIO ATENDIDO  UF\n",
       "0        SBAA  CONCEIÇÃO DO ARAGUAIA  PA\n",
       "1        SBAE                  BAURU  SP\n",
       "2        SBAQ             ARARAQUARA  SP\n",
       "3        SBAR                ARACAJU  SE\n",
       "4        SBAT          ALTA FLORESTA  MT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Localizando e mapenado os aeródromos civis públicos em um novo DataFrame\n",
    "csv_file_path = './dataset/cadastro-de-aerodromos-civis-publicos.csv'\n",
    "\n",
    "try:\n",
    "    airport_df = pd.read_csv(csv_file_path, sep=';')\n",
    "\n",
    "    # Include the 'UF' column\n",
    "    airport_df = airport_df[['CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', 'UF']]\n",
    "\n",
    "    print(\"New DataFrame created with 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', and 'UF' columns:\")\n",
    "    display(airport_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_file_path}\")\n",
    "except KeyError:\n",
    "    print(\"Error: 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', or 'UF' columns not found in the CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 65071,
     "status": "ok",
     "timestamp": 1761941897940,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "9wswJo9p8kN1",
    "outputId": "8c38a4e2-a0fe-421a-f84b-44827aef7cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando merge para DESTINO...\n",
      "Matches encontrados para DESTINO: 17819045/17873941\n",
      "\n",
      "Linhas removidas com ORIGEM ou DESTINO nulos: 108529 (0.61% do total)\n",
      "\n",
      "DataFrame after merging destination airport municipality and removing null values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPRESA</th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>DESTINO</th>\n",
       "      <th>TARIFA</th>\n",
       "      <th>ASSENTOS</th>\n",
       "      <th>MES</th>\n",
       "      <th>ANO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>ARACAJU</td>\n",
       "      <td>851,90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>FOZ DO IGUAÇU</td>\n",
       "      <td>734,90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>RIO DE JANEIRO</td>\n",
       "      <td>832,90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>GUARULHOS</td>\n",
       "      <td>630,90</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>GUARULHOS</td>\n",
       "      <td>928,90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               EMPRESA   ORIGEM         DESTINO  TARIFA  \\\n",
       "21  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI         ARACAJU  851,90   \n",
       "22  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI   FOZ DO IGUAÇU  734,90   \n",
       "23  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI  RIO DE JANEIRO  832,90   \n",
       "24  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI       GUARULHOS  630,90   \n",
       "25  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI       GUARULHOS  928,90   \n",
       "\n",
       "    ASSENTOS  MES   ANO  \n",
       "21         2    1  2023  \n",
       "22         2    1  2023  \n",
       "23         1    1  2023  \n",
       "24         4    1  2023  \n",
       "25         2    1  2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape do DataFrame final: (17765412, 7)\n"
     ]
    }
   ],
   "source": [
    "#Limpeza de dados e merge dos DataFrames para adicionar municípios de origem e destino\n",
    "import pandas as pd\n",
    "\n",
    "# Passo 1: Limpar e padronizar os dados\n",
    "main_df_clean = main_df.copy()\n",
    "airport_df_clean = airport_df.copy()\n",
    "\n",
    "# Limpar espaços e converter para maiúsculas\n",
    "main_df_clean['ORIGEM'] = main_df_clean['ORIGEM'].str.strip().str.upper()\n",
    "main_df_clean['DESTINO'] = main_df_clean['DESTINO'].str.strip().str.upper()\n",
    "airport_df_clean['CÓDIGO OACI'] = airport_df_clean['CÓDIGO OACI'].str.strip().str.upper()\n",
    "\n",
    "if 'CÓDIGO IATA' in airport_df_clean.columns:\n",
    "    airport_df_clean['CÓDIGO IATA'] = airport_df_clean['CÓDIGO IATA'].str.strip().str.upper()\n",
    "\n",
    "# Passo 2: Merge para ORIGEM (que já estava funcionando)\n",
    "merged_origin_df = pd.merge(\n",
    "    main_df_clean,\n",
    "    airport_df_clean,\n",
    "    left_on='ORIGEM',\n",
    "    right_on='CÓDIGO OACI',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renomear e reorganizar ORIGEM\n",
    "merged_origin_df = merged_origin_df.rename(columns={'MUNICÍPIO ATENDIDO': 'MUNICIPIO_ORIGEM'})\n",
    "merged_origin_df = merged_origin_df.drop(columns=['CÓDIGO OACI', 'UF', 'ORIGEM'], errors='ignore')\n",
    "merged_origin_df = merged_origin_df.rename(columns={'MUNICIPIO_ORIGEM': 'ORIGEM'})\n",
    "\n",
    "# Reordenar colunas\n",
    "cols = merged_origin_df.columns.tolist()\n",
    "cols.remove('ORIGEM')\n",
    "cols.insert(cols.index('EMPRESA') + 1, 'ORIGEM')\n",
    "merged_origin_df = merged_origin_df[cols]\n",
    "\n",
    "# Passo 3: Merge para DESTINO com verificação\n",
    "print(\"Verificando merge para DESTINO...\")\n",
    "\n",
    "# Tentar merge com OACI\n",
    "merged_final_df = pd.merge(\n",
    "    merged_origin_df,\n",
    "    airport_df_clean,\n",
    "    left_on='DESTINO',\n",
    "    right_on='CÓDIGO OACI',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verificar resultado\n",
    "matches_destino = merged_final_df['MUNICÍPIO ATENDIDO'].notna().sum()\n",
    "print(f\"Matches encontrados para DESTINO: {matches_destino}/{len(merged_final_df)}\")\n",
    "\n",
    "# Se não encontrou matches, mostrar exemplos problemáticos\n",
    "if matches_destino == 0:\n",
    "    print(\"\\nCódigos problemáticos em DESTINO:\")\n",
    "    problematic_codes = merged_origin_df['DESTINO'].unique()[:10]\n",
    "    for code in problematic_codes:\n",
    "        print(f\"  '{code}' -> Existe em airport_df? {code in airport_df_clean['CÓDIGO OACI'].values}\")\n",
    "\n",
    "# Continuar com o processamento independente do resultado\n",
    "merged_final_df = merged_final_df.rename(columns={'MUNICÍPIO ATENDIDO': 'MUNICIPIO_DESTINO'})\n",
    "merged_final_df = merged_final_df.drop(columns=['CÓDIGO OACI', 'UF', 'DESTINO'], errors='ignore')\n",
    "merged_final_df = merged_final_df.rename(columns={'MUNICIPIO_DESTINO': 'DESTINO'})\n",
    "\n",
    "# Reordenar colunas\n",
    "cols = merged_final_df.columns.tolist()\n",
    "cols.remove('DESTINO')\n",
    "cols.insert(cols.index('ORIGEM') + 1, 'DESTINO')\n",
    "merged_final_df = merged_final_df[cols]\n",
    "\n",
    "# Remover linhas onde ORIGEM ou DESTINO são nulos ou NaN\n",
    "rows_before = len(merged_final_df)\n",
    "merged_final_df = merged_final_df.dropna(subset=['ORIGEM', 'DESTINO'])\n",
    "rows_after = len(merged_final_df)\n",
    "rows_removed = rows_before - rows_after\n",
    "print(f\"\\nLinhas removidas com ORIGEM ou DESTINO nulos: {rows_removed} ({(rows_removed/rows_before)*100:.2f}% do total)\")\n",
    "\n",
    "# Display the head of the final dataframe to verify\n",
    "print(\"\\nDataFrame after merging destination airport municipality and removing null values:\")\n",
    "display(merged_final_df.head())\n",
    "print(f\"\\nShape do DataFrame final: {merged_final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42413,
     "status": "ok",
     "timestamp": 1761942062998,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "RfonZmZTCJ_S",
    "outputId": "b33b90bf-6114-4b48-f5a3-a0aa99e3ffab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores únicos em cada coluna:\n",
      "EMPRESA: 5 valores únicos\n",
      "ORIGEM: 166 valores únicos\n",
      "DESTINO: 165 valores únicos\n",
      "\n",
      "Shape do DataFrame X após encoding: (17765412, 6)\n",
      "\n",
      "Uso de memória otimizado para as features.\n"
     ]
    }
   ],
   "source": [
    "# Preparação dos dados para modelagem com otimização de memória\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Otimizar tipos de dados para reduzir uso de memória\n",
    "merged_final_df['TARIFA'] = merged_final_df['TARIFA'].astype(str).str.replace(',', '.').astype('float32')\n",
    "merged_final_df['MES'] = merged_final_df['MES'].astype('int8')\n",
    "merged_final_df['ANO'] = merged_final_df['ANO'].astype('int16')\n",
    "merged_final_df['ASSENTOS'] = merged_final_df['ASSENTOS'].astype('int32')\n",
    "\n",
    "# Verificar cardinalidade das colunas categóricas\n",
    "print(\"Número de valores únicos em cada coluna:\")\n",
    "for col in ['EMPRESA', 'ORIGEM', 'DESTINO']:\n",
    "    print(f\"{col}: {merged_final_df[col].nunique()} valores únicos\")\n",
    "\n",
    "# Variável alvo\n",
    "y = merged_final_df['ASSENTOS'].values\n",
    "\n",
    "# Criar cópia das features numéricas com tipos otimizados\n",
    "X = merged_final_df[['TARIFA', 'MES', 'ANO']].copy()\n",
    "\n",
    "# Aplicar Label Encoding para cada coluna categórica\n",
    "encoders = {}\n",
    "for col in ['EMPRESA', 'ORIGEM', 'DESTINO']:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(merged_final_df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "    X[col] = X[col].astype('int32')  # Otimizar tipo após encoding\n",
    "\n",
    "print(\"\\nShape do DataFrame X após encoding:\", X.shape)\n",
    "print(\"\\nUso de memória otimizado para as features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7517,
     "status": "ok",
     "timestamp": 1761942070528,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "8a6ZzehCCMJK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados divididos e validação cruzada configurada.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Dividir dados com estratificação para melhor distribuição\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configurar validação cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return r2, rmse\n",
    "\n",
    "print(\"Dados divididos e validação cruzada configurada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138253,
     "status": "ok",
     "timestamp": 1761942344726,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "1QhmcUsh_9TO",
    "outputId": "1dbf3ff9-72ab-410d-93f9-ceb245f129c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - R²: 0.0491, RMSE: 18.51\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Configurar LightGBM com parâmetros otimizados\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_round': 20,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Treinar LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred_lgbm = lgb_model.predict(X_test)\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "print(f\"LightGBM - R²: {r2_lgbm:.4f}, RMSE: {rmse_lgbm:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportando o Modelo e Encoders\n",
    "Vamos salvar o modelo LightGBM treinado e os encoders necessários para uso posterior na API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: ./model_export\\lightgbm_model.pkl\n",
      "Encoders salvos em: ./model_export\\encoders.pkl\n",
      "Informações categóricas salvas em: ./model_export\\categorical_info.json\n",
      "\n",
      "Modelo e dados auxiliares exportados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Criar diretório para os modelos se não existir\n",
    "model_dir = './model_export'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Salvar o modelo LightGBM\n",
    "model_path = os.path.join(model_dir, 'lightgbm_model.pkl')\n",
    "joblib.dump(lgb_model, model_path)\n",
    "\n",
    "# Salvar os encoders\n",
    "encoders_path = os.path.join(model_dir, 'encoders.pkl')\n",
    "joblib.dump(encoders, encoders_path)\n",
    "\n",
    "# Salvar informações adicionais (valores únicos das categorias)\n",
    "import json\n",
    "categorical_info = {\n",
    "    'empresas': merged_final_df['EMPRESA'].unique().tolist(),\n",
    "    'origens': merged_final_df['ORIGEM'].unique().tolist(),\n",
    "    'destinos': merged_final_df['DESTINO'].unique().tolist()\n",
    "}\n",
    "\n",
    "info_path = os.path.join(model_dir, 'categorical_info.json')\n",
    "with open(info_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(categorical_info, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Modelo salvo em: {model_path}\")\n",
    "print(f\"Encoders salvos em: {encoders_path}\")\n",
    "print(f\"Informações categóricas salvas em: {info_path}\")\n",
    "print(\"\\nModelo e dados auxiliares exportados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo e encoders salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Criar diretório para os modelos se não existir\n",
    "model_dir = './model_export'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Salvar o modelo LightGBM\n",
    "model_path = os.path.join(model_dir, 'lightgbm_model.pkl')\n",
    "joblib.dump(lgb_model, model_path)\n",
    "\n",
    "# Salvar os encoders\n",
    "encoders_path = os.path.join(model_dir, 'encoders.pkl')\n",
    "joblib.dump(encoders, encoders_path)\n",
    "\n",
    "print(\"Modelo e encoders salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
