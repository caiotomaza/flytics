{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.13/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: xgboost in ./venv/lib/python3.13/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./venv/lib/python3.13/site-packages (from xgboost) (2.28.7)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from xgboost) (1.16.3)\n",
      "Requirement already satisfied: xgboost in ./venv/lib/python3.13/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./venv/lib/python3.13/site-packages (from xgboost) (2.28.7)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from xgboost) (1.16.3)\n",
      "Requirement already satisfied: lightgbm in ./venv/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./venv/lib/python3.13/site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from lightgbm) (1.16.3)\n",
      "Requirement already satisfied: lightgbm in ./venv/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./venv/lib/python3.13/site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from lightgbm) (1.16.3)\n",
      "Requirement already satisfied: catboost in ./venv/lib/python3.13/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.13/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.13/site-packages (from catboost) (3.10.7)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./venv/lib/python3.13/site-packages (from catboost) (2.3.4)\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.13/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from catboost) (1.16.3)\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.13/site-packages (from catboost) (6.4.0)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.13/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: catboost in ./venv/lib/python3.13/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.13/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.13/site-packages (from catboost) (3.10.7)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./venv/lib/python3.13/site-packages (from catboost) (2.3.4)\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.13/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.13/site-packages (from catboost) (1.16.3)\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.13/site-packages (from catboost) (6.4.0)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.13/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./venv/lib/python3.13/site-packages (from plotly->catboost) (2.10.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.13/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./venv/lib/python3.13/site-packages (from plotly->catboost) (2.10.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "\n",
    "# Pandas\n",
    "!pip install pandas\n",
    "\n",
    "# Scikit-learn\n",
    "!pip install scikit-learn\n",
    "\n",
    "# NumPy\n",
    "!pip install numpy\n",
    "\n",
    "# XGBoost\n",
    "!pip install xgboost\n",
    "\n",
    "# LightGBM\n",
    "!pip install lightgbm\n",
    "\n",
    "# CatBoost\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81447,
     "status": "ok",
     "timestamp": 1761941823117,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "Tu5oPf990JKX",
    "outputId": "16c66339-ae04-411b-9148-a9fe847b4fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando pasta 'backup' pois o nome não é um ano válido.\n",
      "DataFrame combinado criado com sucesso!\n",
      "DataFrame combinado criado com sucesso!\n",
      "  EMPRESA ORIGEM DESTINO   TARIFA  ASSENTOS  MES   ANO\n",
      "0     ABJ   SBSV    SDLO   600,00         8    1  2024\n",
      "1     ABJ   SBSV    SDLO   700,00         8    1  2024\n",
      "2     ABJ   SBSV    SDLO   900,00        14    1  2024\n",
      "3     ABJ   SBSV    SDLO  1550,00         1    1  2024\n",
      "4     ABJ   SBSV    SIRI   650,00        11    1  2024\n",
      "  EMPRESA ORIGEM DESTINO   TARIFA  ASSENTOS  MES   ANO\n",
      "0     ABJ   SBSV    SDLO   600,00         8    1  2024\n",
      "1     ABJ   SBSV    SDLO   700,00         8    1  2024\n",
      "2     ABJ   SBSV    SDLO   900,00        14    1  2024\n",
      "3     ABJ   SBSV    SDLO  1550,00         1    1  2024\n",
      "4     ABJ   SBSV    SIRI   650,00        11    1  2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define o caminho para a pasta que contém as pastas de ano\n",
    "base_folder_path = './dataset/'\n",
    "\n",
    "# Cria uma lista para armazenar os DataFrames de cada arquivo\n",
    "df_list = []\n",
    "\n",
    "# Lista todos os itens na pasta base\n",
    "all_items = os.listdir(base_folder_path)\n",
    "\n",
    "# Filtra apenas as pastas (que devem ser os anos)\n",
    "year_folders = [d for d in all_items if os.path.isdir(os.path.join(base_folder_path, d))]\n",
    "\n",
    "# Itera sobre as pastas de ano\n",
    "for year_folder in year_folders:\n",
    "    year_path = os.path.join(base_folder_path, year_folder)\n",
    "\n",
    "    # Extrai o ano do nome da pasta\n",
    "    try:\n",
    "        year_from_folder = int(year_folder)\n",
    "    except ValueError:\n",
    "        print(f\"Ignorando pasta '{year_folder}' pois o nome não é um ano válido.\")\n",
    "        continue # Skip to the next folder if the name is not a valid year\n",
    "\n",
    "    # Lista todos os arquivos na pasta do ano\n",
    "    year_files = os.listdir(year_path)\n",
    "\n",
    "    # Filtra apenas os arquivos CSV dentro da pasta do ano\n",
    "    csv_files = [f for f in year_files if f.endswith('.CSV')]\n",
    "\n",
    "    # Itera sobre os arquivos CSV dentro da pasta do ano\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(year_path, csv_file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=';')  # Specify semicolon delimiter\n",
    "\n",
    "            # Use the year from the folder\n",
    "            df['ANO'] = year_from_folder\n",
    "\n",
    "            # Convert 'MES' to string before removing comma and converting to numeric\n",
    "            df['MES'] = df['MES'].astype(str).str.replace(',', '', regex=False) # Remove comma\n",
    "            df['MES'] = pd.to_numeric(df['MES'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "            # Create a simple date format (YYYY-MM) - assuming day is not important or always 1\n",
    "            df['DATA'] = pd.to_datetime(df['ANO'].astype(str) + '-' + df['MES'].astype(str), format='%Y-%m', errors='coerce')\n",
    "\n",
    "            # Extract year and month into new columns\n",
    "            df['ANO'] = df['DATA'].dt.year\n",
    "            df['MES'] = df['DATA'].dt.month\n",
    "\n",
    "            # Drop the original date columns\n",
    "            df = df.drop(columns=['nr_ano_referencia', 'nr_mes_referencia', 'DATA'], errors='ignore')\n",
    "\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo {csv_file} na pasta {year_folder}: {e}\")\n",
    "\n",
    "# Concatena todos os DataFrames na lista em um único DataFrame\n",
    "if df_list:\n",
    "    main_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"DataFrame combinado criado com sucesso!\")\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = main_df.columns.tolist()\n",
    "    cols.remove('MES')\n",
    "    cols.remove('ANO')\n",
    "    cols.insert(cols.index('ASSENTOS') + 1, 'MES')\n",
    "    cols.insert(cols.index('ASSENTOS') + 2, 'ANO')\n",
    "    main_df = main_df[cols]\n",
    "\n",
    "    print(main_df.head())\n",
    "else:\n",
    "    print(\"Nenhum arquivo CSV encontrado ou lido nas pastas de ano.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 8900,
     "status": "ok",
     "timestamp": 1761941832029,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "cFnYP4zFB0xP",
    "outputId": "b8c4eac6-aaed-418f-901e-864417ddec6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'EMPRESA' column after replacement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ATA - AEROTÁXI ABAETÉ LTDA.',\n",
       "       'AZUL LINHAS AÉREAS BRASILEIRAS S/A',\n",
       "       'GOL LINHAS AÉREAS S.A. (EX- VRG LINHAS AÉREAS S.A.)', 'PTB',\n",
       "       'TAM LINHAS AÉREAS S.A.', 'APUÍ TÁXI AÉREO S/A'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       EMPRESA ORIGEM DESTINO   TARIFA  ASSENTOS  MES   ANO\n",
      "0  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SDLO   600,00         8    1  2024\n",
      "1  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SDLO   700,00         8    1  2024\n",
      "2  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SDLO   900,00        14    1  2024\n",
      "3  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SDLO  1550,00         1    1  2024\n",
      "4  ATA - AEROTÁXI ABAETÉ LTDA.   SBSV    SIRI   650,00        11    1  2024\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with the mapping of abbreviations to full names\n",
    "empresa_mapping = {\n",
    "    'ABJ': 'ATA - AEROTÁXI ABAETÉ LTDA.',\n",
    "    'AZU': 'AZUL LINHAS AÉREAS BRASILEIRAS S/A',\n",
    "    'GLO': 'GOL LINHAS AÉREAS S.A. (EX- VRG LINHAS AÉREAS S.A.)',\n",
    "    'TAM': 'TAM LINHAS AÉREAS S.A.',\n",
    "    'CQB': 'APUÍ TÁXI AÉREO S/A'\n",
    "}\n",
    "\n",
    "# Replace the abbreviations in the 'EMPRESA' column\n",
    "main_df['EMPRESA'] = main_df['EMPRESA'].replace(empresa_mapping)\n",
    "\n",
    "# Display the updated unique values in the 'EMPRESA' column to verify\n",
    "print(\"Unique values in 'EMPRESA' column after replacement:\")\n",
    "display(main_df['EMPRESA'].unique())\n",
    "\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1761941832246,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "3Tpg5vTTDetC",
    "outputId": "3722101d-3eb3-41c2-835d-d6b85563f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame created with 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', and 'UF' columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CÓDIGO OACI</th>\n",
       "      <th>MUNICÍPIO ATENDIDO</th>\n",
       "      <th>UF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBAA</td>\n",
       "      <td>CONCEIÇÃO DO ARAGUAIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBAE</td>\n",
       "      <td>BAURU</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBAQ</td>\n",
       "      <td>ARARAQUARA</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBAR</td>\n",
       "      <td>ARACAJU</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBAT</td>\n",
       "      <td>ALTA FLORESTA</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CÓDIGO OACI     MUNICÍPIO ATENDIDO  UF\n",
       "0        SBAA  CONCEIÇÃO DO ARAGUAIA  PA\n",
       "1        SBAE                  BAURU  SP\n",
       "2        SBAQ             ARARAQUARA  SP\n",
       "3        SBAR                ARACAJU  SE\n",
       "4        SBAT          ALTA FLORESTA  MT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_file_path = './dataset/cadastro-de-aerodromos-civis-publicos.csv'\n",
    "\n",
    "try:\n",
    "    airport_df = pd.read_csv(csv_file_path, sep=';')\n",
    "\n",
    "    # Include the 'UF' column\n",
    "    airport_df = airport_df[['CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', 'UF']]\n",
    "\n",
    "    print(\"New DataFrame created with 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', and 'UF' columns:\")\n",
    "    display(airport_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_file_path}\")\n",
    "except KeyError:\n",
    "    print(\"Error: 'CÓDIGO OACI', 'MUNICÍPIO ATENDIDO', or 'UF' columns not found in the CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 65071,
     "status": "ok",
     "timestamp": 1761941897940,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "9wswJo9p8kN1",
    "outputId": "8c38a4e2-a0fe-421a-f84b-44827aef7cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando merge para DESTINO...\n",
      "Matches encontrados para DESTINO: 17819045/17873941\n",
      "Matches encontrados para DESTINO: 17819045/17873941\n",
      "\n",
      "Linhas removidas com ORIGEM ou DESTINO nulos: 108529 (0.61% do total)\n",
      "\n",
      "DataFrame after merging destination airport municipality and removing null values:\n",
      "\n",
      "Linhas removidas com ORIGEM ou DESTINO nulos: 108529 (0.61% do total)\n",
      "\n",
      "DataFrame after merging destination airport municipality and removing null values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPRESA</th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>DESTINO</th>\n",
       "      <th>TARIFA</th>\n",
       "      <th>ASSENTOS</th>\n",
       "      <th>MES</th>\n",
       "      <th>ANO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>FORTALEZA</td>\n",
       "      <td>189,90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>ARACATI</td>\n",
       "      <td>SÃO JOSÉ DO RIO PRETO</td>\n",
       "      <td>3764,90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>BAURU</td>\n",
       "      <td>ARACAJU</td>\n",
       "      <td>3694,90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>BAURU</td>\n",
       "      <td>BELÉM</td>\n",
       "      <td>345,90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AZUL LINHAS AÉREAS BRASILEIRAS S/A</td>\n",
       "      <td>BAURU</td>\n",
       "      <td>BELÉM</td>\n",
       "      <td>600,90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               EMPRESA   ORIGEM                DESTINO  \\\n",
       "22  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI              FORTALEZA   \n",
       "23  AZUL LINHAS AÉREAS BRASILEIRAS S/A  ARACATI  SÃO JOSÉ DO RIO PRETO   \n",
       "24  AZUL LINHAS AÉREAS BRASILEIRAS S/A    BAURU                ARACAJU   \n",
       "25  AZUL LINHAS AÉREAS BRASILEIRAS S/A    BAURU                  BELÉM   \n",
       "26  AZUL LINHAS AÉREAS BRASILEIRAS S/A    BAURU                  BELÉM   \n",
       "\n",
       "     TARIFA  ASSENTOS  MES   ANO  \n",
       "22   189,90         1    1  2024  \n",
       "23  3764,90         1    1  2024  \n",
       "24  3694,90         2    1  2024  \n",
       "25   345,90         1    1  2024  \n",
       "26   600,90         1    1  2024  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape do DataFrame final: (17765412, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Passo 1: Limpar e padronizar os dados\n",
    "main_df_clean = main_df.copy()\n",
    "airport_df_clean = airport_df.copy()\n",
    "\n",
    "# Limpar espaços e converter para maiúsculas\n",
    "main_df_clean['ORIGEM'] = main_df_clean['ORIGEM'].str.strip().str.upper()\n",
    "main_df_clean['DESTINO'] = main_df_clean['DESTINO'].str.strip().str.upper()\n",
    "airport_df_clean['CÓDIGO OACI'] = airport_df_clean['CÓDIGO OACI'].str.strip().str.upper()\n",
    "\n",
    "if 'CÓDIGO IATA' in airport_df_clean.columns:\n",
    "    airport_df_clean['CÓDIGO IATA'] = airport_df_clean['CÓDIGO IATA'].str.strip().str.upper()\n",
    "\n",
    "# Passo 2: Merge para ORIGEM (que já estava funcionando)\n",
    "merged_origin_df = pd.merge(\n",
    "    main_df_clean,\n",
    "    airport_df_clean,\n",
    "    left_on='ORIGEM',\n",
    "    right_on='CÓDIGO OACI',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renomear e reorganizar ORIGEM\n",
    "merged_origin_df = merged_origin_df.rename(columns={'MUNICÍPIO ATENDIDO': 'MUNICIPIO_ORIGEM'})\n",
    "merged_origin_df = merged_origin_df.drop(columns=['CÓDIGO OACI', 'UF', 'ORIGEM'], errors='ignore')\n",
    "merged_origin_df = merged_origin_df.rename(columns={'MUNICIPIO_ORIGEM': 'ORIGEM'})\n",
    "\n",
    "# Reordenar colunas\n",
    "cols = merged_origin_df.columns.tolist()\n",
    "cols.remove('ORIGEM')\n",
    "cols.insert(cols.index('EMPRESA') + 1, 'ORIGEM')\n",
    "merged_origin_df = merged_origin_df[cols]\n",
    "\n",
    "# Passo 3: Merge para DESTINO com verificação\n",
    "print(\"Verificando merge para DESTINO...\")\n",
    "\n",
    "# Tentar merge com OACI\n",
    "merged_final_df = pd.merge(\n",
    "    merged_origin_df,\n",
    "    airport_df_clean,\n",
    "    left_on='DESTINO',\n",
    "    right_on='CÓDIGO OACI',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verificar resultado\n",
    "matches_destino = merged_final_df['MUNICÍPIO ATENDIDO'].notna().sum()\n",
    "print(f\"Matches encontrados para DESTINO: {matches_destino}/{len(merged_final_df)}\")\n",
    "\n",
    "# Se não encontrou matches, mostrar exemplos problemáticos\n",
    "if matches_destino == 0:\n",
    "    print(\"\\nCódigos problemáticos em DESTINO:\")\n",
    "    problematic_codes = merged_origin_df['DESTINO'].unique()[:10]\n",
    "    for code in problematic_codes:\n",
    "        print(f\"  '{code}' -> Existe em airport_df? {code in airport_df_clean['CÓDIGO OACI'].values}\")\n",
    "\n",
    "# Continuar com o processamento independente do resultado\n",
    "merged_final_df = merged_final_df.rename(columns={'MUNICÍPIO ATENDIDO': 'MUNICIPIO_DESTINO'})\n",
    "merged_final_df = merged_final_df.drop(columns=['CÓDIGO OACI', 'UF', 'DESTINO'], errors='ignore')\n",
    "merged_final_df = merged_final_df.rename(columns={'MUNICIPIO_DESTINO': 'DESTINO'})\n",
    "\n",
    "# Reordenar colunas\n",
    "cols = merged_final_df.columns.tolist()\n",
    "cols.remove('DESTINO')\n",
    "cols.insert(cols.index('ORIGEM') + 1, 'DESTINO')\n",
    "merged_final_df = merged_final_df[cols]\n",
    "\n",
    "# Remover linhas onde ORIGEM ou DESTINO são nulos ou NaN\n",
    "rows_before = len(merged_final_df)\n",
    "merged_final_df = merged_final_df.dropna(subset=['ORIGEM', 'DESTINO'])\n",
    "rows_after = len(merged_final_df)\n",
    "rows_removed = rows_before - rows_after\n",
    "print(f\"\\nLinhas removidas com ORIGEM ou DESTINO nulos: {rows_removed} ({(rows_removed/rows_before)*100:.2f}% do total)\")\n",
    "\n",
    "# Display the head of the final dataframe to verify\n",
    "print(\"\\nDataFrame after merging destination airport municipality and removing null values:\")\n",
    "display(merged_final_df.head())\n",
    "print(f\"\\nShape do DataFrame final: {merged_final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121991,
     "status": "ok",
     "timestamp": 1761942019952,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "k9sgNQgtB9LA",
    "outputId": "d1e2806d-09c5-4e35-9225-cb7878f4c1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exportado com sucesso para ./validacao.csv\n"
     ]
    }
   ],
   "source": [
    "# Define o caminho e nome do arquivo para exportar\n",
    "output_path = './validacao.csv'\n",
    "\n",
    "# Exporta o DataFrame para CSV\n",
    "try:\n",
    "    merged_final_df.to_csv(output_path, index=False)\n",
    "    print(f\"DataFrame exportado com sucesso para {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao exportar o DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42413,
     "status": "ok",
     "timestamp": 1761942062998,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "RfonZmZTCJ_S",
    "outputId": "b33b90bf-6114-4b48-f5a3-a0aa99e3ffab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores únicos em cada coluna:\n",
      "EMPRESA: 5 valores únicos\n",
      "EMPRESA: 5 valores únicos\n",
      "ORIGEM: 166 valores únicos\n",
      "ORIGEM: 166 valores únicos\n",
      "DESTINO: 165 valores únicos\n",
      "DESTINO: 165 valores únicos\n",
      "\n",
      "Shape do DataFrame X após encoding: (17765412, 6)\n",
      "\n",
      "Uso de memória otimizado para as features.\n",
      "\n",
      "Shape do DataFrame X após encoding: (17765412, 6)\n",
      "\n",
      "Uso de memória otimizado para as features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Otimizar tipos de dados para reduzir uso de memória\n",
    "merged_final_df['TARIFA'] = merged_final_df['TARIFA'].astype(str).str.replace(',', '.').astype('float32')\n",
    "merged_final_df['MES'] = merged_final_df['MES'].astype('int8')\n",
    "merged_final_df['ANO'] = merged_final_df['ANO'].astype('int16')\n",
    "merged_final_df['ASSENTOS'] = merged_final_df['ASSENTOS'].astype('int32')\n",
    "\n",
    "# Verificar cardinalidade das colunas categóricas\n",
    "print(\"Número de valores únicos em cada coluna:\")\n",
    "for col in ['EMPRESA', 'ORIGEM', 'DESTINO']:\n",
    "    print(f\"{col}: {merged_final_df[col].nunique()} valores únicos\")\n",
    "\n",
    "# Variável alvo\n",
    "y = merged_final_df['ASSENTOS'].values\n",
    "\n",
    "# Criar cópia das features numéricas com tipos otimizados\n",
    "X = merged_final_df[['TARIFA', 'MES', 'ANO']].copy()\n",
    "\n",
    "# Aplicar Label Encoding para cada coluna categórica\n",
    "encoders = {}\n",
    "for col in ['EMPRESA', 'ORIGEM', 'DESTINO']:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(merged_final_df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "    X[col] = X[col].astype('int32')  # Otimizar tipo após encoding\n",
    "\n",
    "print(\"\\nShape do DataFrame X após encoding:\", X.shape)\n",
    "print(\"\\nUso de memória otimizado para as features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7517,
     "status": "ok",
     "timestamp": 1761942070528,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "8a6ZzehCCMJK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados divididos e validação cruzada configurada.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Dividir dados com estratificação para melhor distribuição\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configurar validação cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return r2, rmse\n",
    "\n",
    "print(\"Dados divididos e validação cruzada configurada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6865,
     "status": "ok",
     "timestamp": 1761942077411,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "nntG2cyHCNuC",
    "outputId": "f4517573-80f5-4eb9-d5d6-f2a7574b8b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Linear - R²: 0.0127, RMSE: 18.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "print(f\"Regressão Linear - R²: {r2_lr:.4f}, RMSE: {rmse_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129066,
     "status": "ok",
     "timestamp": 1761942206495,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "9fd741a6",
    "outputId": "a38294f9-c3c0-4db0-81de-c9f0c088039b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - R²: 0.0491, RMSE: 18.54\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Configurar XGBoost com parâmetros otimizados\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 20\n",
    "}\n",
    "\n",
    "# Treinar XGBoost\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"XGBoost - R²: {r2_xgb:.4f}, RMSE: {rmse_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138253,
     "status": "ok",
     "timestamp": 1761942344726,
     "user": {
      "displayName": "Caio Tomaz",
      "userId": "01025468359002248467"
     },
     "user_tz": 180
    },
    "id": "1QhmcUsh_9TO",
    "outputId": "1dbf3ff9-72ab-410d-93f9-ceb245f129c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - R²: 0.0503, RMSE: 18.53\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Configurar LightGBM com parâmetros otimizados\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_round': 20,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Treinar LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred_lgbm = lgb_model.predict(X_test)\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "print(f\"LightGBM - R²: {r2_lgbm:.4f}, RMSE: {rmse_lgbm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOSk5cFn0ZTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - R²: 0.0416, RMSE: 18.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Treinar Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "print(f\"Gradient Boosting - R²: {r2_gb:.4f}, RMSE: {rmse_gb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ASJ_pKNk0jj0"
   },
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Configurar CatBoost com parâmetros otimizados\n",
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_seed': 42,\n",
    "    'loss_function': 'RMSE',\n",
    "    'thread_count': -1,\n",
    "    'verbose': False,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "# Treinar CatBoost\n",
    "catboost_model = cb.CatBoostRegressor(**catboost_params)\n",
    "catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "r2_catboost = r2_score(y_test, y_pred_catboost)\n",
    "rmse_catboost = np.sqrt(mean_squared_error(y_test, y_pred_catboost))\n",
    "print(f\"CatBoost - R²: {r2_catboost:.4f}, RMSE: {rmse_catboost:.2f}\")\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "catboost_model.save_model('best_catboost_model.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTzRi3Xg0lgR"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Treinar AdaBoost\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "r2_ada = r2_score(y_test, y_pred_ada)\n",
    "rmse_ada = np.sqrt(mean_squared_error(y_test, y_pred_ada))\n",
    "print(f\"AdaBoost - R²: {r2_ada:.4f}, RMSE: {rmse_ada:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
